{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5652a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: matplotlib in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (3.8.2)\n",
      "Requirement already satisfied: imageio in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (2.31.1)\n",
      "Requirement already satisfied: gdown in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (4.7.1)\n",
      "Requirement already satisfied: tensorflow in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (2.13.0rc1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.45.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: filelock in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from gdown) (3.12.2)\n",
      "Requirement already satisfied: requests[socks] in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.13.0rc1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.23.3)\n",
      "Requirement already satisfied: setuptools in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (67.7.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.56.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0rc0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.1rc0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from requests[socks]->gdown) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (6.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/srujithraoambati/Library/Python/3.9/lib/python/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python matplotlib imageio gdown tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb7949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5f6c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices=tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7634a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e07ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(units=20, activation='relu', input_shape=(10,5)))\n",
    "\n",
    "print(model_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f923aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ddc389",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "output = 'data.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4801c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]: \n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        # frames.append(frame[190:236,80:220,:])\n",
    "        frames.append(frame[150:236,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e2f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_video(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]: \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7210d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "\n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3bc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/s1/yyyyy.mpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('/')[-1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = load_data(tf.convert_to_tensor(test_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100cab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# Added for split\n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = data.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c5b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9844a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30efbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = sample.next(); val[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cfe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(val[0][0][35])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49edee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f70290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,86,140,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c0af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(val[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.strings.reduce_join([num_to_char(tf.argmax(x)) for x in yhat[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afdcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaab4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa5ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):\n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524370bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=legacy.Adam(learning_rate=0.0001), loss=CTCLoss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816130df",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_callback = ProduceExample(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e64155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=test, epochs=2, callbacks=[checkpoint_callback, schedule_callback, example_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dcac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/s1/bbc.mp4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31cd27e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No faces detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"./data/s1/yyyyy.mpg\"\n",
      "[ERROR:0@628.030] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): ./data/s1/yyyyy.mpg in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained face cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Specify the path to the video file\n",
    "test_path = './data/s1/yyyyy.mpg'\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(test_path)\n",
    "\n",
    "# Array to store cropped faces\n",
    "cropped_faces = []\n",
    "\n",
    "# Process video frame by frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Store cropped faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Crop the frame to the size of the detected face\n",
    "        cropped_face = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Apply histogram equalization to enhance pixels\n",
    "        cropped_face_eq = cv2.equalizeHist(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2GRAY))\n",
    "        cropped_faces.append(cropped_face_eq)\n",
    "\n",
    "# Release video capture\n",
    "cap.release()\n",
    "\n",
    "# Plot the first cropped face if any were detected\n",
    "if cropped_faces:\n",
    "    plt.imshow(cropped_faces[140])  # First cropped face\n",
    "    plt.title('First Cropped Face (Enhanced)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No faces detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cropped_faces)):\n",
    "    plt.imshow(cv2.cvtColor(cropped_faces[i], cv2.COLOR_BGR2RGB))  # First cropped face\n",
    "    plt.title('First Cropped Face (Resized)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No faces detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.transforms import ToTensor\n",
    "import RRDBNet_arch as arch\n",
    "\n",
    "# Load pre-trained face cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the pre-trained Real-ESRGAN model\n",
    "model_path = 'models/RRDB_ESRGAN_x4.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = arch.RRDBNet(3, 3, 64, 23, gc=32).to(device)\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Preprocess the input image\n",
    "input_image = Image.open(\"me.png\")\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "\n",
    "preprocess = ToTensor()\n",
    "input_tensor = preprocess(input_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Perform image enhancement\n",
    "with torch.no_grad():\n",
    "    enhanced_tensor = model(input_tensor).clamp(0.0, 1.0)\n",
    "\n",
    "# Postprocess the enhanced image\n",
    "postprocess = ToPILImage()\n",
    "enhanced_image = postprocess(enhanced_tensor.squeeze(0).cpu())\n",
    "\n",
    "# Save or display the enhanced image\n",
    "enhanced_image.save(\"enhanced_image.jpg\")\n",
    "enhanced_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image.save(\"enhanced_image.jpg\")\n",
    "enhanced_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
